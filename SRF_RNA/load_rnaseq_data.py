#!/usr/bin/env python3
"""
Script to load and process bulk RNA-seq data from featureCounts output.
This script loads the counts data from the file generated by featureCounts
and provides basic functionality for data exploration and analysis.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
from pathlib import Path

def load_featurecounts(counts_file):
    """
    Load featureCounts output file into a pandas DataFrame.
    
    Parameters:
    -----------
    counts_file : str
        Path to the featureCounts output file
        
    Returns:
    --------
    tuple
        (counts_df, metadata_df) where:
        - counts_df: DataFrame with gene counts (rows: genes, columns: samples)
        - metadata_df: DataFrame with gene metadata (rows: genes, columns: metadata fields)
    """
    print(f"Loading counts data from: {counts_file}")
    
    # Read the file, skipping the first comment line
    df = pd.read_csv(counts_file, sep='\t', skiprows=1)
    
    # Extract the metadata columns (first 6 columns)
    metadata_cols = ['Geneid', 'Chr', 'Start', 'End', 'Strand', 'Length']
    metadata_df = df[metadata_cols].copy()
    
    # Extract the count columns (all columns except metadata)
    counts_df = df.drop(columns=metadata_cols)
    
    # Clean up sample names in the count columns
    # Extract just the sample name from the full path
    counts_df.columns = [os.path.basename(os.path.dirname(col)) for col in counts_df.columns]
    
    # Set Geneid as index for both dataframes
    metadata_df.set_index('Geneid', inplace=True)
    counts_df.set_index(df['Geneid'], inplace=True)
    
    print(f"Loaded data for {counts_df.shape[1]} samples and {counts_df.shape[0]} genes")
    
    return counts_df, metadata_df

def normalize_counts(counts_df, method='cpm'):
    """
    Normalize count data using specified method.
    
    Parameters:
    -----------
    counts_df : pandas.DataFrame
        DataFrame with raw counts
    method : str
        Normalization method: 'cpm' (counts per million) or 'log2cpm' (log2 of CPM)
        
    Returns:
    --------
    pandas.DataFrame
        Normalized counts
    """
    if method == 'cpm':
        # CPM normalization
        norm_df = counts_df.copy()
        for col in norm_df.columns:
            col_sum = norm_df[col].sum()
            norm_df[col] = (norm_df[col] / col_sum) * 1e6
        return norm_df
    
    elif method == 'log2cpm':
        # Log2 CPM normalization (with pseudocount of 1)
        norm_df = counts_df.copy()
        for col in norm_df.columns:
            col_sum = norm_df[col].sum()
            norm_df[col] = np.log2(((norm_df[col] / col_sum) * 1e6) + 1)
        return norm_df
    
    else:
        raise ValueError(f"Unknown normalization method: {method}")

def filter_low_counts(counts_df, min_count=10, min_samples=3):
    """
    Filter out genes with low counts.
    
    Parameters:
    -----------
    counts_df : pandas.DataFrame
        DataFrame with raw counts
    min_count : int
        Minimum count threshold
    min_samples : int
        Minimum number of samples that must exceed the threshold
        
    Returns:
    --------
    pandas.DataFrame
        Filtered counts dataframe
    """
    # Count samples where gene count exceeds threshold
    keep_genes = (counts_df >= min_count).sum(axis=1) >= min_samples
    
    # Filter the dataframe
    filtered_df = counts_df.loc[keep_genes]
    
    print(f"Filtered from {counts_df.shape[0]} to {filtered_df.shape[0]} genes")
    return filtered_df

def plot_sample_distributions(counts_df, output_dir=None, log_scale=True):
    """
    Plot the distribution of counts across samples.
    
    Parameters:
    -----------
    counts_df : pandas.DataFrame
        DataFrame with counts
    output_dir : str, optional
        Directory to save the plot
    log_scale : bool
        Whether to use log scale for y-axis
    """
    plt.figure(figsize=(12, 8))
    
    # Create boxplot
    ax = sns.boxplot(data=counts_df)
    
    # Rotate x-axis labels
    plt.xticks(rotation=90)
    
    # Set log scale if requested
    if log_scale:
        plt.yscale('log')
    
    plt.title('Count Distribution Across Samples')
    plt.ylabel('Counts' if not log_scale else 'Counts (log scale)')
    plt.tight_layout()
    
    # Save or show the plot
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
        plt.savefig(os.path.join(output_dir, 'sample_distributions.png'), dpi=300)
    else:
        plt.show()
    
    plt.close()

def plot_pca(norm_df, metadata=None, color_by=None, output_dir=None):
    """
    Perform PCA and plot the results.
    
    Parameters:
    -----------
    norm_df : pandas.DataFrame
        DataFrame with normalized counts
    metadata : pandas.DataFrame, optional
        DataFrame with sample metadata
    color_by : str, optional
        Column in metadata to use for coloring points
    output_dir : str, optional
        Directory to save the plot
    """
    from sklearn.decomposition import PCA
    
    # Transpose to get samples as rows
    data = norm_df.T
    
    # Perform PCA
    pca = PCA(n_components=2)
    pca_result = pca.fit_transform(data)
    
    # Create DataFrame with PCA results
    pca_df = pd.DataFrame(data=pca_result, columns=['PC1', 'PC2'])
    pca_df.index = data.index
    
    # Calculate variance explained
    var_explained = pca.explained_variance_ratio_ * 100
    
    # Create plot
    plt.figure(figsize=(10, 8))
    
    if metadata is not None and color_by is not None and color_by in metadata.columns:
        # Add metadata for coloring
        pca_df = pca_df.join(metadata[color_by])
        
        # Plot with colors
        sns.scatterplot(data=pca_df, x='PC1', y='PC2', hue=color_by, s=100)
    else:
        # Simple plot without coloring
        sns.scatterplot(data=pca_df, x='PC1', y='PC2', s=100)
    
    # Add sample labels
    for idx, row in pca_df.iterrows():
        plt.annotate(idx, (row['PC1'], row['PC2']), 
                     xytext=(5, 5), textcoords='offset points')
    
    # Set axis labels with variance explained
    plt.xlabel(f'PC1 ({var_explained[0]:.2f}%)')
    plt.ylabel(f'PC2 ({var_explained[1]:.2f}%)')
    
    plt.title('PCA of RNA-seq Samples')
    plt.tight_layout()
    
    # Save or show the plot
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
        plt.savefig(os.path.join(output_dir, 'pca_plot.png'), dpi=300)
    else:
        plt.show()
    
    plt.close()
    
    return pca_df

def create_sample_metadata(counts_df):
    """
    Create a basic metadata DataFrame from sample names.
    
    Parameters:
    -----------
    counts_df : pandas.DataFrame
        DataFrame with counts
        
    Returns:
    --------
    pandas.DataFrame
        Sample metadata
    """
    # Extract sample names
    samples = counts_df.columns.tolist()
    
    # Extract condition from sample name (assuming format like C1, GFP2, YAF3)
    conditions = []
    for sample in samples:
        # Extract letters from the beginning of the sample name
        condition = ''.join([c for c in sample if c.isalpha()])
        conditions.append(condition)
    
    # Create metadata DataFrame
    metadata = pd.DataFrame({
        'sample': samples,
        'condition': conditions
    })
    metadata.set_index('sample', inplace=True)
    
    return metadata

def main():
    """Main function to demonstrate usage of the module."""
    # Define paths
    counts_file = "results/counts/all_samples_counts.txt"
    output_dir = "results/analysis"
    
    # Check if the counts file exists
    if not os.path.exists(counts_file):
        # Try with absolute path
        base_dir = os.path.dirname(os.path.abspath(__file__))
        counts_file = os.path.join(base_dir, counts_file)
        if not os.path.exists(counts_file):
            print(f"Error: Could not find counts file at {counts_file}")
            return
    
    # Load the data
    counts_df, metadata_df = load_featurecounts(counts_file)
    
    # Display basic information
    print("\nSample counts:")
    print(counts_df.sum().sort_values(ascending=False))
    
    # Filter low-count genes
    filtered_df = filter_low_counts(counts_df, min_count=10, min_samples=3)
    
    # Normalize the data
    norm_df = normalize_counts(filtered_df, method='log2cpm')
    
    # Create sample metadata
    sample_metadata = create_sample_metadata(counts_df)
    print("\nSample metadata:")
    print(sample_metadata)
    
    # Create output directory
    os.makedirs(output_dir, exist_ok=True)
    
    # Generate plots
    print("\nGenerating plots...")
    plot_sample_distributions(counts_df, output_dir=output_dir)
    plot_pca(norm_df, metadata=sample_metadata, color_by='condition', output_dir=output_dir)
    
    print(f"\nAnalysis complete. Results saved to {output_dir}")
    
    # Return the dataframes for interactive use
    return counts_df, metadata_df, norm_df, sample_metadata

if __name__ == "__main__":
    main()
