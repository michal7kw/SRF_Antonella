from os.path import join
import pandas as pd

# Configuration
CONFIG = {
    'samples': ['C1', 'C2', 'C3', 'GFP1', 'GFP2', 'GFP3', 'YAF1', 'YAF2', 'YAF3'],
    'conditions': ['C', 'GFP', 'YAF'],
    'genome_dir': '/beegfs/scratch/ric.broccoli/kubacki.michal/SRF_H2AK119Ub_cross_V5/COMMON_DATA/genome_star',  # Directory for STAR genome index
    'genome_fasta': '/beegfs/scratch/ric.broccoli/kubacki.michal/SRF_H2AK119Ub_cross_V5/COMMON_DATA/genome/Homo_sapiens.GRCh38.dna.primary_assembly.fa',  # Path to genome fasta
    'gtf': '/beegfs/scratch/ric.broccoli/kubacki.michal/SRF_H2AK119Ub_cross_V5/COMMON_DATA/gencode.v43.basic.annotation.nochr.gtf',  # Basic Gencode v43 annotation for GRCh38 (without chr prefix)
    'max_threads': 32,  # Maximum threads for heavy processes
    'medium_threads': 16,  # Medium thread count for moderate processes
    'light_threads': 4,  # Light thread count for simple processes
    'chrom_sizes': '/beegfs/scratch/ric.broccoli/kubacki.michal/SRF_H2AK119Ub_cross_V5/COMMON_DATA/genome/Homo_sapiens.GRCh38.dna.primary_assembly.chrom.sizes',  # Chromosome sizes for bigWig generation
    # Define comparisons for differential expression analysis
    'comparisons': [
        ('GFP', 'C'),  # GFP vs Control
        ('YAF', 'C'),  # YAF vs Control
        ('YAF', 'GFP')  # YAF vs GFP
    ]
}

# Create sample to condition mapping
SAMPLE_TO_CONDITION = {}
for sample in CONFIG['samples']:
    for condition in CONFIG['conditions']:
        if sample.startswith(condition):
            SAMPLE_TO_CONDITION[sample] = condition

# Create metadata table for DESeq2
metadata = pd.DataFrame({
    'sample': CONFIG['samples'],
    'condition': [SAMPLE_TO_CONDITION[s] for s in CONFIG['samples']]
})
metadata.to_csv('metadata.csv', index=False)

# Output directories
RESULTS_DIR = 'results'
LOGS_DIR = 'logs'

# Final output files for the complete pipeline
rule all:
    input:
        # FastQC reports
        expand(join(RESULTS_DIR, 'fastqc', '{sample}_L001_R1_001_fastqc.html'), sample=CONFIG['samples']),
        expand(join(RESULTS_DIR, 'fastqc', '{sample}_L001_R2_001_fastqc.html'), sample=CONFIG['samples']),
        # Trimmed FastQC reports
        expand(join(RESULTS_DIR, 'fastqc', '{sample}_R1_trimmed_fastqc.html'), sample=CONFIG['samples']),
        expand(join(RESULTS_DIR, 'fastqc', '{sample}_R2_trimmed_fastqc.html'), sample=CONFIG['samples']),
        # STAR alignments
        expand(join(RESULTS_DIR, 'star', '{sample}', '{sample}_Aligned.sortedByCoord.out.bam'), sample=CONFIG['samples']),
        # BAM indices
        expand(join(RESULTS_DIR, 'star', '{sample}', '{sample}_Aligned.sortedByCoord.out.bam.bai'), sample=CONFIG['samples']),
        # featureCounts results
        join(RESULTS_DIR, 'counts', 'all_samples_counts.txt'),
        # BigWig files
        expand(join(RESULTS_DIR, 'bigwig', '{sample}.bw'), sample=CONFIG['samples']),
        # DESeq2 results
        expand(join(RESULTS_DIR, 'deseq2', '{condition1}_vs_{condition2}', 'differential_expression.csv'), 
               zip, condition1=[comp[0] for comp in CONFIG['comparisons']], condition2=[comp[1] for comp in CONFIG['comparisons']]),
        # DESeq2 visualizations
        expand(join(RESULTS_DIR, 'deseq2', '{condition1}_vs_{condition2}', 'MA_plot.pdf'), 
               zip, condition1=[comp[0] for comp in CONFIG['comparisons']], condition2=[comp[1] for comp in CONFIG['comparisons']]),
        expand(join(RESULTS_DIR, 'deseq2', '{condition1}_vs_{condition2}', 'volcano_plot.pdf'), 
               zip, condition1=[comp[0] for comp in CONFIG['comparisons']], condition2=[comp[1] for comp in CONFIG['comparisons']]),
        # PCA plot
        join(RESULTS_DIR, 'deseq2', 'pca_plot.pdf'),
        # Heatmap of top DEGs
        join(RESULTS_DIR, 'deseq2', 'top_degs_heatmap.pdf'),
        # Sample correlation heatmap
        join(RESULTS_DIR, 'deseq2', 'sample_correlation_heatmap.pdf'),
        # MultiQC report
        join(RESULTS_DIR, 'multiqc', 'multiqc_report.html')

# FastQC on raw reads
rule fastqc_raw:
    input:
        r1 = join('DATA', '{sample}', '{sample}_L001_R1_001.fastq.gz'),
        r2 = join('DATA', '{sample}', '{sample}_L001_R2_001.fastq.gz')
    output:
        html_r1 = join(RESULTS_DIR, 'fastqc', '{sample}_L001_R1_001_fastqc.html'),
        html_r2 = join(RESULTS_DIR, 'fastqc', '{sample}_L001_R2_001_fastqc.html'),
        zip_r1 = join(RESULTS_DIR, 'fastqc', '{sample}_L001_R1_001_fastqc.zip'),
        zip_r2 = join(RESULTS_DIR, 'fastqc', '{sample}_L001_R2_001_fastqc.zip')
    log:
        join(LOGS_DIR, 'fastqc', '{sample}.log')
    threads: CONFIG['light_threads']
    resources:
        mem_mb=4000,
        time='2h'
    shell:
        'fastqc -o {RESULTS_DIR}/fastqc -t {threads} {input.r1} {input.r2} 2> {log}'

# Trimmomatic PE
rule trimmomatic:
    input:
        r1 = join('DATA', '{sample}', '{sample}_L001_R1_001.fastq.gz'),
        r2 = join('DATA', '{sample}', '{sample}_L001_R2_001.fastq.gz')
    output:
        r1 = join(RESULTS_DIR, 'trimmed', '{sample}_R1_trimmed.fastq.gz'),
        r2 = join(RESULTS_DIR, 'trimmed', '{sample}_R2_trimmed.fastq.gz'),
        r1_unpaired = join(RESULTS_DIR, 'trimmed', '{sample}_R1_unpaired.fastq.gz'),
        r2_unpaired = join(RESULTS_DIR, 'trimmed', '{sample}_R2_unpaired.fastq.gz')
    log:
        join(LOGS_DIR, 'trimmomatic', '{sample}.log')
    threads: CONFIG['medium_threads']
    resources:
        mem_mb=16000,
        time='4h'
    shell:
        'trimmomatic PE -threads {threads} '
        '{input.r1} {input.r2} '
        '{output.r1} {output.r1_unpaired} '
        '{output.r2} {output.r2_unpaired} '
        'ILLUMINACLIP:TruSeq3-PE.fa:2:30:10 '
        'LEADING:3 TRAILING:3 '
        'SLIDINGWINDOW:4:15 '
        'MINLEN:36 '
        '2> {log}'

# FastQC on trimmed reads
rule fastqc_trimmed:
    input:
        r1 = rules.trimmomatic.output.r1,
        r2 = rules.trimmomatic.output.r2
    output:
        html_r1 = join(RESULTS_DIR, 'fastqc', '{sample}_R1_trimmed_fastqc.html'),
        html_r2 = join(RESULTS_DIR, 'fastqc', '{sample}_R2_trimmed_fastqc.html'),
        zip_r1 = join(RESULTS_DIR, 'fastqc', '{sample}_R1_trimmed_fastqc.zip'),
        zip_r2 = join(RESULTS_DIR, 'fastqc', '{sample}_R2_trimmed_fastqc.zip')
    log:
        join(LOGS_DIR, 'fastqc_trimmed', '{sample}.log')
    threads: 2
    shell:
        'fastqc -o {RESULTS_DIR}/fastqc -t {threads} {input.r1} {input.r2} 2> {log}'

# STAR genome indexing
rule star_index:
    input:
        fasta = CONFIG['genome_fasta'],
        gtf = CONFIG['gtf']
    output:
        touch(join(LOGS_DIR, 'star_index', 'index_complete.flag'))
    params:
        genome_dir = CONFIG['genome_dir']
    log:
        join(LOGS_DIR, 'star_index', 'star_index.log')
    threads: 1
    resources:
        mem_mb=4000,
        time='5m'
    shell:
        # Only check for the existence of the index
        'echo "Checking for STAR index in {params.genome_dir}" > {log} && '
        'if [ ! -d "{params.genome_dir}" ] || [ ! -f "{params.genome_dir}/genomeParameters.txt" ]; then '
        '    echo "STAR index not found or incomplete. Please run the build_star_index.sh script first." >> {log}; '
        '    echo "Run: sbatch scripts/build_star_index.sh" >> {log}; '
        '    exit 1; '
        'else '
        '    echo "STAR index found and appears to be complete" >> {log}; '
        '    touch {output}; '
        'fi'

# STAR alignment
rule star_align:
    input:
        r1 = rules.trimmomatic.output.r1,
        r2 = rules.trimmomatic.output.r2,
        index_flag = rules.star_index.output
    output:
        bam = join(RESULTS_DIR, 'star', '{sample}', '{sample}_Aligned.sortedByCoord.out.bam'),
        log = join(RESULTS_DIR, 'star', '{sample}', '{sample}_Log.final.out')
    params:
        outdir = join(RESULTS_DIR, 'star', '{sample}'),
        prefix = join(RESULTS_DIR, 'star', '{sample}', '{sample}_'),
        genome_dir = CONFIG['genome_dir']
    log:
        join(LOGS_DIR, 'star', '{sample}.log')
    threads: CONFIG['max_threads']
    resources:
        mem_mb=48000,
        time='8h'
    shell:
        'STAR '
        '--runThreadN {threads} '
        '--genomeDir {params.genome_dir} '
        '--readFilesIn {input.r1} {input.r2} '
        '--readFilesCommand zcat '
        '--outFileNamePrefix {params.prefix} '
        '--outSAMtype BAM SortedByCoordinate '
        '--outSAMattributes Standard '
        '--limitBAMsortRAM 45000000000 '
        '2> {log}'

# Index BAM files
rule index_bam:
    input:
        rules.star_align.output.bam
    output:
        join(RESULTS_DIR, 'star', '{sample}', '{sample}_Aligned.sortedByCoord.out.bam.bai')
    log:
        join(LOGS_DIR, 'samtools_index', '{sample}.log')
    shell:
        # Check if the index already exists and is newer than the BAM file
        'if [ -f {output} ] && [ {output} -nt {input} ]; then '
        '    echo "BAM index already exists and is up-to-date, skipping indexing" > {log}; '
        'else '
        '    samtools index {input} 2> {log}; '
        'fi'

# featureCounts
rule featurecounts:
    input:
        bams = expand(join(RESULTS_DIR, 'star', '{sample}', '{sample}_Aligned.sortedByCoord.out.bam'), sample=CONFIG['samples'])
    output:
        counts = join(RESULTS_DIR, 'counts', 'all_samples_counts.txt'),
        summary = join(RESULTS_DIR, 'counts', 'all_samples_counts.txt.summary')
    log:
        join(LOGS_DIR, 'featurecounts', 'all_samples.log')
    threads: CONFIG['max_threads']
    resources:
        mem_mb=32000,
        time='6h'
    shell:
        'featureCounts '
        '-T {threads} '
        '-p -t exon -g gene_id '
        '-a {CONFIG[gtf]} '
        '-o {output.counts} '
        '{input.bams} '
        '2> {log}'

# Generate bigWig files from BAM
rule bam_to_bigwig:
    input:
        bam = join(RESULTS_DIR, 'star', '{sample}', '{sample}_Aligned.sortedByCoord.out.bam'),
        bai = join(RESULTS_DIR, 'star', '{sample}', '{sample}_Aligned.sortedByCoord.out.bam.bai')
    output:
        bigwig = join(RESULTS_DIR, 'bigwig', '{sample}.bw')
    log:
        join(LOGS_DIR, 'bigwig', '{sample}.log')
    threads: CONFIG['medium_threads']
    resources:
        mem_mb=32000,
        time='4h'
    shell:
        'bamCoverage '
        '--bam {input.bam} '
        '--outFileName {output.bigwig} '
        '--outFileFormat bigwig '
        '--binSize 10 '
        '--normalizeUsing RPKM '
        '--effectiveGenomeSize 2913022398 '
        '--numberOfProcessors {threads} '
        '2> {log}'

# Prepare count matrix for DESeq2
rule prepare_count_matrix:
    input:
        counts = join(RESULTS_DIR, 'counts', 'all_samples_counts.txt')
    output:
        matrix = join(RESULTS_DIR, 'deseq2', 'count_matrix.csv')
    log:
        join(LOGS_DIR, 'deseq2', 'prepare_count_matrix.log')
    script:
        'scripts/prepare_count_matrix.R'

# Run DESeq2 differential expression analysis
rule deseq2_analysis:
    input:
        counts = join(RESULTS_DIR, 'deseq2', 'count_matrix.csv'),
        metadata = 'metadata.csv'
    output:
        results = join(RESULTS_DIR, 'deseq2', '{condition1}_vs_{condition2}', 'differential_expression.csv'),
        normalized_counts = join(RESULTS_DIR, 'deseq2', '{condition1}_vs_{condition2}', 'normalized_counts.csv'),
        rds = join(RESULTS_DIR, 'deseq2', '{condition1}_vs_{condition2}', 'dds.rds'),
        ma_plot = join(RESULTS_DIR, 'deseq2', '{condition1}_vs_{condition2}', 'MA_plot.pdf'),
        volcano_plot = join(RESULTS_DIR, 'deseq2', '{condition1}_vs_{condition2}', 'volcano_plot.pdf')
    params:
        condition1 = '{condition1}',
        condition2 = '{condition2}'
    log:
        join(LOGS_DIR, 'deseq2', '{condition1}_vs_{condition2}.log')
    resources:
        mem_mb=32000,
        time='2h'
    script:
        'scripts/run_deseq2.R'

# Generate PCA plot and sample correlation heatmap
rule deseq2_visualizations:
    input:
        dds_files = expand(join(RESULTS_DIR, 'deseq2', '{condition1}_vs_{condition2}', 'dds.rds'),
                          zip, condition1=[comp[0] for comp in CONFIG['comparisons']], 
                          condition2=[comp[1] for comp in CONFIG['comparisons']]),
        metadata = 'metadata.csv'
    output:
        pca = join(RESULTS_DIR, 'deseq2', 'pca_plot.pdf'),
        heatmap = join(RESULTS_DIR, 'deseq2', 'sample_correlation_heatmap.pdf'),
        top_degs_heatmap = join(RESULTS_DIR, 'deseq2', 'top_degs_heatmap.pdf')
    log:
        join(LOGS_DIR, 'deseq2', 'visualizations.log')
    resources:
        mem_mb=32000,
        time='2h'
    script:
        'scripts/deseq2_visualizations.R'

# MultiQC report
rule multiqc:
    input:
        expand(join(RESULTS_DIR, 'fastqc', '{sample}_L001_R1_001_fastqc.zip'), sample=CONFIG['samples']),
        expand(join(RESULTS_DIR, 'fastqc', '{sample}_L001_R2_001_fastqc.zip'), sample=CONFIG['samples']),
        expand(join(RESULTS_DIR, 'fastqc', '{sample}_R1_trimmed_fastqc.zip'), sample=CONFIG['samples']),
        expand(join(RESULTS_DIR, 'fastqc', '{sample}_R2_trimmed_fastqc.zip'), sample=CONFIG['samples']),
        expand(join(RESULTS_DIR, 'star', '{sample}', '{sample}_Log.final.out'), sample=CONFIG['samples']),
        join(RESULTS_DIR, 'counts', 'all_samples_counts.txt.summary')
    output:
        report = join(RESULTS_DIR, 'multiqc', 'multiqc_report.html')
    log:
        join(LOGS_DIR, 'multiqc', 'multiqc.log')
    shell:
        'multiqc '
        '--force '
        '-o {RESULTS_DIR}/multiqc '
        '{RESULTS_DIR}/fastqc '
        '{RESULTS_DIR}/star '
        '{RESULTS_DIR}/counts '
        '{RESULTS_DIR}/deseq2 '
        '2> {log}'
