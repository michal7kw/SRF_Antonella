import os
from glob import glob

# Configuration
configfile: "config.yaml"

# Define samples
SAMPLES = ["SRR18590296", "SRR18590297"]  # SESV5ChIPSeq1S5 and SESV5ChIPSeq2S6
INPUT_SAMPLE = "SRR18590303"  # InputSESV5ChIPSeqS2

# Define directory structure
RESULT_DIR = "results"  # Base directory for all outputs
LOG_DIR = "logs"        # Directory for all logs

rule all:
    input:
        # Quality control outputs
        expand("results/qc/fastqc/{sample}_{read}_fastqc.html", 
               sample=SAMPLES + [INPUT_SAMPLE], read=[1,2]),
        "results/qc/multiqc/multiqc_report.html",
        # Alignment outputs
        expand("results/alignment/{sample}.sorted.bam", sample=SAMPLES + [INPUT_SAMPLE]),
        expand("results/alignment/{sample}.sorted.bam.bai", sample=SAMPLES + [INPUT_SAMPLE]),
        # Deduplicated BAM files
        expand("results/alignment/{sample}.dedup.bam", sample=SAMPLES + [INPUT_SAMPLE]),
        expand("results/alignment/{sample}.dedup.metrics.txt", sample=SAMPLES + [INPUT_SAMPLE]),
        # Peak calling outputs
        expand("results/peaks/{sample}_narrow_peaks.narrowPeak", sample=SAMPLES),
        expand("results/peaks/{sample}_broad_peaks.broadPeak", sample=SAMPLES),
        # BigWig files
        expand("results/bigwig/{sample}.bw", sample=SAMPLES + [INPUT_SAMPLE])

rule fastqc:
    input:
        r1="data_from_ncbi/{sample}_1.fastq",
        r2="data_from_ncbi/{sample}_2.fastq"
    output:
        html1="results/qc/fastqc/{sample}_1_fastqc.html",
        html2="results/qc/fastqc/{sample}_2_fastqc.html"
    log:
        "logs/fastqc/{sample}.log"
    benchmark:
        "logs/benchmarks/fastqc/{sample}.tsv"
    threads: 4
    resources:
        mem_mb=8000
    shell:
        """
        mkdir -p results/qc/fastqc
        fastqc -t {threads} -o results/qc/fastqc {input.r1} {input.r2} 2> {log}
        """

rule multiqc:
    input:
        expand("results/qc/fastqc/{sample}_{read}_fastqc.html",
               sample=SAMPLES + [INPUT_SAMPLE],
               read=[1,2])
    output:
        html="results/qc/multiqc/multiqc_report.html"
    log:
        "logs/multiqc/multiqc.log"
    benchmark:
        "logs/benchmarks/multiqc/multiqc.tsv"
    resources:
        mem_mb=4000,
        runtime=60
    threads: 1
    shell:
        """
        mkdir -p results/qc/multiqc
        multiqc results/qc/fastqc \
            --outdir results/qc/multiqc \
            --filename multiqc_report.html \
            2> {log}
        """

rule align:
    input:
        r1="data_from_ncbi/{sample}_1.fastq",
        r2="data_from_ncbi/{sample}_2.fastq"
    output:
        bam="results/alignment/{sample}.sorted.bam",
        bai="results/alignment/{sample}.sorted.bam.bai"
    params:
        index=config["genome_index"],
        tmp_dir=temp(directory("results/alignment/tmp_{sample}"))
    log:
        "logs/align/{sample}.log"
    benchmark:
        "logs/benchmarks/align/{sample}.tsv"
    threads: 8
    resources:
        mem_mb=32000,
        runtime=1440
    shell:
        """
        set -e
        
        # Ensure directories exist
        mkdir -p results/alignment
        mkdir -p $(dirname {log})
        mkdir -p {params.tmp_dir}
        
        # Check if index files exist (check for all required bowtie2 index files)
        for ext in 1.bt2 2.bt2 3.bt2 4.bt2 rev.1.bt2 rev.2.bt2; do
            if [ ! -f {params.index}.${{ext}} ]; then
                echo "Error: Bowtie2 index file {params.index}.${{ext}} not found" >&2
                exit 1
            fi
        done
        
        # Check input files
        if [ ! -f {input.r1} ] || [ ! -f {input.r2} ]; then
            echo "Error: Input fastq files not found" >&2
            exit 1
        fi
        
        # Run alignment with read statistics logging
        (bowtie2 --very-sensitive \
            -p {threads} \
            -x {params.index} \
            -1 {input.r1} \
            -2 {input.r2} \
            --rg-id '{wildcards.sample}' \
            --rg 'SM:{wildcards.sample}' \
            --rg 'PL:ILLUMINA' \
            --rg 'LB:lib1' \
            --met-file {log}.metrics \
            --no-unal) 2> {log} | \
        samtools sort \
            -@ {threads} \
            -T {params.tmp_dir} \
            -m 2G \
            -o {output.bam}
            
        # Index BAM file
        samtools index {output.bam}
        """

rule deduplicate_bam:
    input:
        bam="results/alignment/{sample}.sorted.bam"
    output:
        bam="results/alignment/{sample}.dedup.bam",
        bai="results/alignment/{sample}.dedup.bam.bai",
        metrics="results/alignment/{sample}.dedup.metrics.txt"
    log:
        "logs/dedup/{sample}.log"
    benchmark:
        "logs/benchmarks/dedup/{sample}.tsv"
    threads: 8
    resources:
        mem_mb=32000
    shell:
        """
        picard MarkDuplicates \
            I={input.bam} \
            O={output.bam} \
            M={output.metrics} \
            REMOVE_DUPLICATES=true \
            VALIDATION_STRINGENCY=LENIENT \
            2> {log} && \
        samtools index {output.bam}
        """

rule call_narrow_peaks:
    input:
        treatment="results/alignment/{sample}.dedup.bam",
        control=f"results/alignment/{INPUT_SAMPLE}.dedup.bam"
    output:
        "results/peaks/{sample}_narrow_peaks.narrowPeak"
    params:
        genome_size=config["genome_size"],
        prefix="results/peaks/{sample}_narrow"
    log:
        "logs/macs2/{sample}_narrow.log"
    benchmark:
        "logs/benchmarks/macs2/{sample}_narrow.tsv"
    threads: 8
    resources:
        mem_mb=32000
    shell:
        """
        mkdir -p results/peaks
        macs2 callpeak \
            -t {input.treatment} \
            -c {input.control} \
            -f BAMPE \
            -g {params.genome_size} \
            -n {params.prefix} \
            -q 0.05 \
            --nomodel \
            --extsize 200 \
            --keep-dup all \
            --call-summits \
            2> {log}
        """

rule call_broad_peaks:
    input:
        treatment="results/alignment/{sample}.dedup.bam",
        control=f"results/alignment/{INPUT_SAMPLE}.dedup.bam"
    output:
        "results/peaks/{sample}_broad_peaks.broadPeak"
    params:
        genome_size=config["genome_size"],
        prefix="results/peaks/{sample}_broad"
    log:
        "logs/macs2/{sample}_broad.log"
    benchmark:
        "logs/benchmarks/macs2/{sample}_broad.tsv"
    threads: 8
    resources:
        mem_mb=32000
    shell:
        """
        mkdir -p results/peaks
        macs2 callpeak \
            -t {input.treatment} \
            -c {input.control} \
            -f BAMPE \
            -g {params.genome_size} \
            -n {params.prefix} \
            -q 0.05 \
            --broad \
            --broad-cutoff 0.1 \
            --nomodel \
            --extsize 200 \
            --keep-dup all \
            2> {log}
        """

rule create_bigwig:
    input:
        bam="results/alignment/{sample}.dedup.bam",
        bai="results/alignment/{sample}.dedup.bam.bai"
    output:
        "results/bigwig/{sample}.bw"
    log:
        "logs/bigwig/{sample}.log"
    benchmark:
        "logs/benchmarks/bigwig/{sample}.tsv"
    threads: 8
    resources:
        mem_mb=32000
    shell:
        """
        mkdir -p results/bigwig
        bamCoverage -b {input.bam} -o {output} \
            --binSize 50 \
            --smoothLength 150 \
            --normalizeUsing RPGC \
            --effectiveGenomeSize 2864785220 \
            --extendReads \
            --numberOfProcessors {threads} \
            2> {log}
        """
